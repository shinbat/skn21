{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LinearRegression from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현할 것\n",
    "- 공부시간과 성적간의 관계를 모델링한다.\n",
    "    - **머신러닝 모델(모형)이란** 수집한 데이터를 기반으로 입력값(Feature)와 출력값(Target)간의 관계를 하나의 공식으로 정의한 함수이다. 그 공식을 찾는 과정을 **모델링**이라고 한다.\n",
    "    - 이 예제에서는 공부한 시험시간으로 점수를 예측하는 모델을 정의한다.\n",
    "    - 입력값과 출력값 간의 관계를 정의할 수있는 다양한 함수(공식)이 있다. 여기에서는 딥러닝과 관계가 있는 **Linear Regression** 을 사용해본다.\n",
    "\n",
    "# 데이터 확인\n",
    "- 입력데이터: 공부시간\n",
    "- 출력데이터: 성적\n",
    "\n",
    "|공부시간|점수|\n",
    "|-|-|\n",
    "|1|20|\n",
    "|2|40|\n",
    "|3|60|\n",
    "\n",
    "우리가 수집한 공부시간과 점수 데이터를 바탕으로 둘 간의 관계를 식으로 정의 할 수 있으면 **내가 몇시간 공부하면 점수를 얼마 받을 수 있는지 예측할 수 있게 된다.**   \n",
    "수집한 데이터를 기반으로 앞으로 예측할 수있는 모형을 만드는 것이 머신러닝 모델링이다.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습(훈련) 데이터셋 만들기\n",
    "- 모델을 학습시키기 위한 데이터셋을 구성한다.\n",
    "- 입력데이터와 출력데이터을 각각 다른 행렬로 구성한다.\n",
    "- 하나의 데이터 포인트의 입력/출력 값은 같은 index에 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀 (Linear Regression)\n",
    "- Feature들의 가중합을 이용해 Target을 추정한다.\n",
    "- Feature에 곱해지는 가중치(weight)들은 각 Feature가 Target 얼마나 영향을 주는지 영향도가 된다.\n",
    "    - 음수일 경우는 target값을 줄이고 양수일 경우는 target값을 늘린다.\n",
    "    - 가중치가 0에 가까울 수록 target에 영향을 주지 않는 feature이고 0에서 멀수록 target에 많은 영향을 준다.\n",
    "- 모델 학습과정에서 가장 적절한 Feature의 가중치를 찾아야 한다.\n",
    "      \n",
    "\n",
    "\\begin{align}\n",
    "&\\large \\hat{y} = W\\cdot X + b\\\\\n",
    "&\\small \\hat{y}: \\text{모델추정값}\\\\\n",
    "&\\small W: \\text{가중치}\\\\\n",
    "&\\small X: \\text{Feature(입력값)}\\\\\n",
    "&\\small b: \\text{bias(편향)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset 구성\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `공부시간` 1개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다.   \n",
    "  이 문제에서 예측할 항목은 `시험점수` 한개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.tensor([[1], [2], [3]], dtype=torch.float32)          # 공부시간\n",
    "y_train = torch.tensor([[20], [40], [60]], dtype=torch.float32)       # 시험점수\n",
    "X_train.size(), y_train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 (weight, bias) 정의\n",
    "- 학습대상/최적화 대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1])\n",
      "tensor([[-0.5216]], requires_grad=True)\n",
      "tensor([0.2398], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "weight = torch.randn(1, 1, requires_grad=True)      # feature에 곱할 값(가중치)\n",
    "# (1: 입력 feature개수, 1: 출력값(예측)의 개수)\n",
    "bias = torch.randn(1, requires_grad=True)       # bias 값\n",
    "print(weight.size(), bias.size())\n",
    "print(weight)\n",
    "print(bias)\n",
    "\n",
    "# 정규분포에 따라서 weight, bias를 랜덤반영후, 바꿔나간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론\n",
    "pred = X_train @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.],\n",
       "        [40.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1945.6740], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차계산\n",
    "loss = torch.mean((y_train - pred)**2, dim=0)\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient계산 -> loss에 대한 weight, bias의 순간변화율(gradient)를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-190.5757]]), tensor([-81.6068]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3310]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "weight.data = weight.data - weight.grad * lr\n",
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3310]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## 업데이트된 파라미터로 추정 -> loss 계산\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pred2 = \u001b[43mX\u001b[49m @ weight + bias\n\u001b[32m      3\u001b[39m loss2 = torch.mean((pred2 - y)**\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "## 업데이트된 파라미터로 추정 -> loss 계산\n",
    "pred2 = X @ weight + bias\n",
    "loss2 = torch.mean((pred2 - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(loss.item(), \u001b[43mloss2\u001b[49m.item())\n",
      "\u001b[31mNameError\u001b[39m: name 'loss2' is not defined"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "weight = torch.randn(1, 1, requires_grad=True)\n",
    "bias =  torch.randn(1, requires_grad=True) \n",
    "\n",
    "# 추론 모델\n",
    "def linear_model(X):\n",
    "    return X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(오차) 계산 함수\n",
    "def mse_loss_fn(pred, y):\n",
    "    return torch.mean((pred-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "1. 모델을 이용해 추정한다.\n",
    "   - pred = model(input)\n",
    "1. loss를 계산한다.\n",
    "   - loss = loss_fn(pred, target)\n",
    "1. 계산된 loss를 파라미터에 대해 미분하여 계산한 gradient 값을 각 파라미터에 저장한다.\n",
    "   - loss.backward()\n",
    "1. optimizer를 이용해 파라미터를 update한다.\n",
    "   - optimizer.step()  \n",
    "1. 파라미터의 gradient(미분값)을 0으로 초기화한다.\n",
    "   - optimizer.zero_grad()\n",
    "- 위의 단계를 반복한다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2000] - loss: 1875.2142\n",
      "[100/2000] - loss: 4.8689\n",
      "[200/2000] - loss: 3.0087\n",
      "[300/2000] - loss: 1.8592\n",
      "[400/2000] - loss: 1.1489\n",
      "[500/2000] - loss: 0.7099\n",
      "[600/2000] - loss: 0.4387\n",
      "[700/2000] - loss: 0.2711\n",
      "[800/2000] - loss: 0.1675\n",
      "[900/2000] - loss: 0.1035\n",
      "[1000/2000] - loss: 0.0640\n",
      "[1100/2000] - loss: 0.0395\n",
      "[1200/2000] - loss: 0.0244\n",
      "[1300/2000] - loss: 0.0151\n",
      "[1400/2000] - loss: 0.0093\n",
      "[1500/2000] - loss: 0.0058\n",
      "[1600/2000] - loss: 0.0036\n",
      "[1700/2000] - loss: 0.0022\n",
      "[1800/2000] - loss: 0.0014\n",
      "[1900/2000] - loss: 0.0008\n",
      "[1999/2000] - loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000 # train set을 몇 번 학습할지.\n",
    "lr = 0.01\n",
    "for epoch in range(epochs):\n",
    "    #1. 추론(예측)\n",
    "    pred = linear_model(X_train)\n",
    "    # 2. 오차계산\n",
    "    loss = mse_loss_fn(pred, y_train)\n",
    "    # 3. 파라미터들(weight, bias)에 대한 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data -lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "\n",
    "    # 마지막 epoch, 100 epoch 마다 loss를 출력(성능개선 상황을 모니터링)\n",
    "    if epoch % 100 == 0 or epoch == (epochs-1):\n",
    "        print(f'[{epoch}/{epochs}] - loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19.9735]]), tensor([0.0602]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data, bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 99.9278],\n",
      "        [139.8749]])\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "with torch.no_grad():\n",
    "    new_X = torch.tensor([[5],  [7]], dtype=torch.float32)\n",
    "    pred =  linear_model(new_X)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 입력, 다중 출력\n",
    "- 다중입력: Feature가 여러개인 경우\n",
    "- 다중출력: Output 결과가 여러개인 경우\n",
    "\n",
    "다음 가상 데이터를 이용해 사과와 오렌지 수확량을 예측하는 선형회귀 모델을 정의한다.  \n",
    "[참조](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)\n",
    "\n",
    "\n",
    "|온도(F)|강수량(mm)|습도(%)|사과생산량(ton)|오렌지생산량|\n",
    "|-|-|-|-:|-:|\n",
    "|73|67|43|56|70|\n",
    "|91|88|64|81|101|\n",
    "|87|134|58|119|133|\n",
    "|102|43|37|22|37|\n",
    "|69|96|70|103|119|\n",
    "\n",
    "```\n",
    "사과수확량  = w11 * 온도 + w12 * 강수량 + w13 * 습도 + b1\n",
    "오렌지수확량 = w21 * 온도 + w22 * 강수량 + w23 *습도 + b2\n",
    "```\n",
    "\n",
    "- `온도`, `강수량`, `습도` 값이 **사과**와, **오렌지 수확량**에 어느정도 영향을 주는지 가중치를 찾는다.\n",
    "    - 모델은 사과의 수확량, 오렌지의 수확량 **두개의 예측결과를 출력**해야 한다.\n",
    "    - 사과에 대해 예측하기 위한 weight 3개와 오렌지에 대해 예측하기 위한 weight 3개 이렇게 두 묶음, 총 6개의 weight를 정의하고 학습을 통해 가장 적당한 값을 찾는다.\n",
    "        - `개별 과일를 예측하기 위한 weight들 @ feature들` 의 계산 결과를  **Node, Unit, Neuron** 이라고 한다.\n",
    "        - 두 과일에 대한 Unit들을 묶어서 **Layer** 라고 한다.\n",
    "- 목적은 우리가 수집한 train 데이터셋을 이용해 **정확한 예측을 위한 weight와 bias 들**을 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `온도, 강수량, 습도` 세개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다. 이 문제에서 예측할 항목은 `사과수확량, 오렌지 수확량` 2개의 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input: 생산환경 (temp, rainfall, humidity) : (5, 3)\n",
    "environs = [\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "]\n",
    "\n",
    "# Targets: 생산량 - (apples, oranges) - (5, 2)\n",
    "apple_orange_output = [\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Dataset을 torch.Tensor로 생성\n",
    "X = torch.tensor(environs, dtype=torch.float32)\n",
    "y = torch.tensor(apple_orange_output, dtype=torch.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight와 bias\n",
    "- weight: 각 feature들이 생산량에 영향을 주었는지의 가중치로 feature에 곱해줄 값.\n",
    "    - 사과, 오렌지의 생산량을 구해야 하므로 가중치가 두개가 된다.\n",
    "    - weight의 shape: `(3, 2)`\n",
    "- bias는 모든 feature들이 0일때 생산량이 얼마일지를 나타내는 값으로 feature와 weight간의 가중합 결과에 더해줄 값이다.\n",
    "    - 사과, 오렌지의 생산량을 구하므로 bias가 두개가 된다.\n",
    "    - bias의 shape: `(2, )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model\n",
    "모델은 weights `w`와 inputs `x`의 내적(dot product)한 값에 bias `b`를 더하는 함수.\n",
    "\n",
    "$$\n",
    "\\hspace{2.5cm} X \\hspace{1.1cm} \\cdot \\hspace{1.2cm} W \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{cc}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "69 & 96 & 70\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\cdot\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "$w_{11},\\,w_{12},\\,w_{13}$: 사과 생산량 계산시 각 feature들(생산환경)에 곱할 가중치   <br>\n",
    "$w_{21},\\,w_{22},\\,w_{23}$: 오렌지 생산량 계산시 각 feature들(생산환경)에 곱할 가중치    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/kgmyhGit/image_resource/main/deeplearning/figures/3_unit_layer.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight/bias 를 정의 -> 초기값은 random 값을 이용해서 생성.\n",
    "# 사과(3,1) 오랜지(3,1) => (3,2)\n",
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "weight.size(), bias.size()\n",
    "# weight: (3:input feature개수  ,  2:output 개수)\n",
    "# bias  : (2:output 개수, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3852,  0.7991],\n",
       "        [-0.0565, -1.4666],\n",
       "        [ 0.5994, -2.9609]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2074,  0.6727], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 학습(최적화)\n",
    "## 추론\n",
    "pred = X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 120.8963, -166.5709],\n",
       "        [ 157.2295, -245.1635],\n",
       "        [ 145.4914, -298.0587],\n",
       "        [ 158.8270,  -90.4326],\n",
       "        [ 129.8997, -292.2423]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred.size())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(57713.5312, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loss 계산(MSE)\n",
    "loss = torch.mean((pred - y)**2) # 전체 추론한 결과의 평균오차를 계산.\n",
    "# dim=0 이라서 생략, 1축의 각각 평균값을 구한다 ((((아주중요하다))))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss를 가지고 파라미터들(weight들, bias들)의 gradient 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3852,  0.7991],\n",
       "        [-0.0565, -1.4666],\n",
       "        [ 0.5994, -2.9609]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5958.2988, -25529.3008],\n",
       "        [  4614.4048, -29806.6719],\n",
       "        [  3230.2610, -18166.0762]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.2074,  0.6727]), tensor([  66.2688, -310.4936]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 업데이트\n",
    "lr = 0.00001\n",
    "weight.data = weight.data - lr * weight.grad\n",
    "bias.data = bias.data - lr * bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3256,  1.0544],\n",
       "        [-0.1027, -1.1685],\n",
       "        [ 0.5671, -2.7792]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2080,  0.6758])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 업데이트된 파라미터로 추정 -> loss 계산\n",
    "pred2 = X @ weight + bias\n",
    "loss2 = torch.mean((pred2 - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57713.53125 40069.62109375\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "## 모델 정의\n",
    "def model(X):\n",
    "    return X @ weight + bias\n",
    "\n",
    "## loss 함수(MSE)\n",
    "def loss_fn(pred, y):\n",
    "    return torch.mean((pred - y)**2) # 전체 오차의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 28658.15234\n",
      "[0101/5000] - 478.17441\n",
      "[0201/5000] - 268.72638\n",
      "[0301/5000] - 187.09286\n",
      "[0401/5000] - 145.22025\n",
      "[0501/5000] - 117.73602\n",
      "[0601/5000] - 96.97023\n",
      "[0701/5000] - 80.31356\n",
      "[0801/5000] - 66.65492\n",
      "[0901/5000] - 55.36839\n",
      "[1001/5000] - 46.01749\n",
      "[1101/5000] - 38.26314\n",
      "[1201/5000] - 31.83101\n",
      "[1301/5000] - 26.49506\n",
      "[1401/5000] - 22.06826\n",
      "[1501/5000] - 18.39566\n",
      "[1601/5000] - 15.34885\n",
      "[1701/5000] - 12.82111\n",
      "[1801/5000] - 10.72402\n",
      "[1901/5000] - 8.98423\n",
      "[2001/5000] - 7.54086\n",
      "[2101/5000] - 6.34339\n",
      "[2201/5000] - 5.34994\n",
      "[2301/5000] - 4.52576\n",
      "[2401/5000] - 3.84200\n",
      "[2501/5000] - 3.27473\n",
      "[2601/5000] - 2.80409\n",
      "[2701/5000] - 2.41364\n",
      "[2801/5000] - 2.08972\n",
      "[2901/5000] - 1.82099\n",
      "[3001/5000] - 1.59804\n",
      "[3101/5000] - 1.41308\n",
      "[3201/5000] - 1.25963\n",
      "[3301/5000] - 1.13232\n",
      "[3401/5000] - 1.02670\n",
      "[3501/5000] - 0.93908\n",
      "[3601/5000] - 0.86639\n",
      "[3701/5000] - 0.80607\n",
      "[3801/5000] - 0.75604\n",
      "[3901/5000] - 0.71453\n",
      "[4001/5000] - 0.68010\n",
      "[4101/5000] - 0.65153\n",
      "[4201/5000] - 0.62782\n",
      "[4301/5000] - 0.60816\n",
      "[4401/5000] - 0.59185\n",
      "[4501/5000] - 0.57832\n",
      "[4601/5000] - 0.56708\n",
      "[4701/5000] - 0.55777\n",
      "[4801/5000] - 0.55004\n",
      "[4901/5000] - 0.54363\n",
      "[5000/5000] - 0.53835\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "lr = 0.00001  # 1e-5\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추론\n",
    "    pred = model(X)\n",
    "    \n",
    "    # 2. loss 계산\n",
    "    loss = loss_fn(pred, y)\n",
    "    # 3. 파라미터 들의 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    ## 100 epoch, 마지막 epoch에서 loss를 출력 => 학습 과정 log를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1557,  70.3218],\n",
       "        [ 82.1155, 100.5501],\n",
       "        [118.9158, 133.2111],\n",
       "        [ 21.1457,  37.0862],\n",
       "        [101.6980, 118.8856]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터로 추론\n",
    "p = model(X)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = torch.tensor([68, 82, 56], dtype=torch.float32)     \n",
    "new_x = new_x.unsqueeze(dim=0)      # 갯수는 없고 feature차원만 3개가 있다. # 차원을 늘려야함\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[80.7039, 95.4518]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[80.7039, 95.4518]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    p = model(new_x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch built-in 모델을 사용해 Linear Regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[73, 67, 43], \n",
    "     [91, 88, 64], \n",
    "     [87, 134, 58], \n",
    "     [102, 43, 37], \n",
    "     [69, 96, 70]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [[56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Linear\n",
    "Pytorch는 torch.nn.Linear 클래스를 통해 Linear Regression 모델을 제공한다.  \n",
    "torch.nn.Linear에 입력 feature의 개수와 출력 값의 개수를 지정하면 random 값으로 초기화한 weight와 bias들을 생성해 모델을 구성한다.\n",
    "- `torch.nn.Linear(input feature의 개수 , output 값의 개수)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer와 Loss 함수 정의\n",
    "- **Optimizer**: 계산된 gradient값을 이용해 파라미터들을 업데이트 하는 함수\n",
    "- **Loss 함수**: 정답과 모델이 예측한 값사이의 차이(오차)를 계산하는 함수.\n",
    "  - 모델을 최적화하는 것은 이 함수의 값을 최소화하는 것을 말한다. \n",
    "- `torch.optim` 모듈에 다양한 Optimizer 클래스가 구현되있다.\n",
    "- `torch.nn` 또는 `torch.nn.functional` 모듈에 다양한 Loss 함수가 제공된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 모델을 정의. torch.nn.Linear 클래스\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(3, 2)  # 3: input feature 개수, 2: output 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5124,  0.2481, -0.4609],\n",
       "        [-0.4701, -0.3148, -0.0482]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4915, -0.2913], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수\n",
    "loss_fn = torch.nn.MSELoss()  # 클래스\n",
    "# loss_fn = torch.nn.functional.mse_loss # 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer (torch.optim 모듈에 정의): weight.data = weight.data - lr * weight.grad\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), # 최적화 대상 파라미터들을 model에서 조회해서 전달.\n",
    "    lr = 0.00001,       # Learning Rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5124,  0.2481, -0.4609],\n",
       "         [-0.4701, -0.3148, -0.0482]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4915, -0.2913], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 22035.392578125\n",
      "[0101/5000] - 86.82661437988281\n",
      "[0201/5000] - 42.61507797241211\n",
      "[0301/5000] - 27.161218643188477\n",
      "[0401/5000] - 20.296295166015625\n",
      "[0501/5000] - 16.272275924682617\n",
      "[0601/5000] - 13.402826309204102\n",
      "[0701/5000] - 11.153837203979492\n",
      "[0801/5000] - 9.32496166229248\n",
      "[0901/5000] - 7.8180365562438965\n",
      "[1001/5000] - 6.570757865905762\n",
      "[1101/5000] - 5.536813735961914\n",
      "[1201/5000] - 4.679247856140137\n",
      "[1301/5000] - 3.967844009399414\n",
      "[1401/5000] - 3.3776824474334717\n",
      "[1501/5000] - 2.888061046600342\n",
      "[1601/5000] - 2.481865882873535\n",
      "[1701/5000] - 2.144866466522217\n",
      "[1801/5000] - 1.8652822971343994\n",
      "[1901/5000] - 1.633338212966919\n",
      "[2001/5000] - 1.440915584564209\n",
      "[2101/5000] - 1.2812716960906982\n",
      "[2201/5000] - 1.1488254070281982\n",
      "[2301/5000] - 1.0389471054077148\n",
      "[2401/5000] - 0.9477857351303101\n",
      "[2501/5000] - 0.8721662759780884\n",
      "[2601/5000] - 0.8094202280044556\n",
      "[2701/5000] - 0.7573724985122681\n",
      "[2801/5000] - 0.7141802906990051\n",
      "[2901/5000] - 0.6783550977706909\n",
      "[3001/5000] - 0.6486328840255737\n",
      "[3101/5000] - 0.6239716410636902\n",
      "[3201/5000] - 0.6035143733024597\n",
      "[3301/5000] - 0.5865431427955627\n",
      "[3401/5000] - 0.5724585056304932\n",
      "[3501/5000] - 0.5607811808586121\n",
      "[3601/5000] - 0.551092267036438\n",
      "[3701/5000] - 0.5430511236190796\n",
      "[3801/5000] - 0.5363799333572388\n",
      "[3901/5000] - 0.5308437943458557\n",
      "[4001/5000] - 0.5262536406517029\n",
      "[4101/5000] - 0.5224430561065674\n",
      "[4201/5000] - 0.5192843079566956\n",
      "[4301/5000] - 0.5166637301445007\n",
      "[4401/5000] - 0.5144885778427124\n",
      "[4501/5000] - 0.5126842260360718\n",
      "[4601/5000] - 0.511188268661499\n",
      "[4701/5000] - 0.5099477171897888\n",
      "[4801/5000] - 0.5089133381843567\n",
      "[4901/5000] - 0.5080575346946716\n",
      "[5000/5000] - 0.5073543787002563\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 추론\n",
    "    pred = model(inputs)  \n",
    "    # loss 계산\n",
    "    loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "    # gradient 계산\n",
    "    loss.backward()\n",
    "\n",
    "    # 파라미터 업데이트: optimizer.step()\n",
    "    optimizer.step()        # w = w - lr * g\n",
    "\n",
    "    # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 현재 epoch 학습 결과를 log로 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 => gradient 계산을 할 필요가 없다. ==> grad_fn을 만들 필요가 없다. 그래서 torch.no_grad() 블록에서 추론 작업을 실행한다.\n",
    "with torch.no_grad():\n",
    "    pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.0902,  70.2647],\n",
       "        [ 82.2064, 100.6722],\n",
       "        [118.8132, 133.0243],\n",
       "        [ 21.1217,  37.0375],\n",
       "        [101.8006, 119.0723]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 로직을 함수 구현\n",
    "def train(inputs, targets, epochs, model, loss_fn, optimizer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 추론\n",
    "        pred = model(inputs)\n",
    "        # loss 계산\n",
    "        loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트: optimizer.step()\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "        optimizer.zero_grad()\n",
    "        # 현재 epoch 학습 결과를 log로 출력\n",
    "        if epoch % 100 == 0 or epoch == epochs-1:\n",
    "            print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 5952.8251953125\n",
      "[0101/5000] - 12.488027572631836\n",
      "[0201/5000] - 2.3456554412841797\n",
      "[0301/5000] - 0.7915058732032776\n",
      "[0401/5000] - 0.5533300638198853\n",
      "[0501/5000] - 0.5168267488479614\n",
      "[0601/5000] - 0.5112279057502747\n",
      "[0701/5000] - 0.5103666186332703\n",
      "[0801/5000] - 0.510233998298645\n",
      "[0901/5000] - 0.5102073550224304\n",
      "[1001/5000] - 0.5102006196975708\n",
      "[1101/5000] - 0.5101960897445679\n",
      "[1201/5000] - 0.5101892948150635\n",
      "[1301/5000] - 0.5101851224899292\n",
      "[1401/5000] - 0.5101823806762695\n",
      "[1501/5000] - 0.5101789832115173\n",
      "[1601/5000] - 0.510170578956604\n",
      "[1701/5000] - 0.5101674199104309\n",
      "[1801/5000] - 0.5101617574691772\n",
      "[1901/5000] - 0.5101593732833862\n",
      "[2001/5000] - 0.5101538300514221\n",
      "[2101/5000] - 0.5101478099822998\n",
      "[2201/5000] - 0.5101467370986938\n",
      "[2301/5000] - 0.5101404786109924\n",
      "[2401/5000] - 0.5101372003555298\n",
      "[2501/5000] - 0.5101321935653687\n",
      "[2601/5000] - 0.5101304054260254\n",
      "[2701/5000] - 0.5101226568222046\n",
      "[2801/5000] - 0.5101204514503479\n",
      "[2901/5000] - 0.5101151466369629\n",
      "[3001/5000] - 0.5101097822189331\n",
      "[3101/5000] - 0.5101062655448914\n",
      "[3201/5000] - 0.5101023316383362\n",
      "[3301/5000] - 0.5100972652435303\n",
      "[3401/5000] - 0.5100940465927124\n",
      "[3501/5000] - 0.5100902915000916\n",
      "[3601/5000] - 0.5100834369659424\n",
      "[3701/5000] - 0.5100792646408081\n",
      "[3801/5000] - 0.5100716352462769\n",
      "[3901/5000] - 0.5100734233856201\n",
      "[4001/5000] - 0.5100672245025635\n",
      "[4101/5000] - 0.5100611448287964\n",
      "[4201/5000] - 0.5100554823875427\n",
      "[4301/5000] - 0.510054349899292\n",
      "[4401/5000] - 0.5100468397140503\n",
      "[4501/5000] - 0.510043203830719\n",
      "[4601/5000] - 0.5100412368774414\n",
      "[4701/5000] - 0.510038435459137\n",
      "[4801/5000] - 0.5100325345993042\n",
      "[4901/5000] - 0.510026216506958\n",
      "[5000/5000] - 0.5100230574607849\n"
     ]
    }
   ],
   "source": [
    "train(inputs, targets, 5000, model, nn.functional.mse_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
